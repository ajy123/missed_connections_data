{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "708137ee-d116-4f98-b82e-3f08519f0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import altair as alt\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5ca363e-59eb-4874-83ed-65f00f1a5bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>post</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>borough</th>\n",
       "      <th>tokenized_post</th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>adj</th>\n",
       "      <th>emojis_adj</th>\n",
       "      <th>emojis_noun</th>\n",
       "      <th>emojis_verb</th>\n",
       "      <th>emojis</th>\n",
       "      <th>cleaned_emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>https://newyork.craigslist.org/mnh/mis/d/new-y...</td>\n",
       "      <td>2024-06-24 10:59:00</td>\n",
       "      <td>\\nPort Authority guy by escalator (Midtown)</td>\n",
       "      <td>40.7547</td>\n",
       "      <td>-73.9925</td>\n",
       "      <td>In Porth Authority yesterday around 7pm</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>1900-01-01 10:59:00</td>\n",
       "      <td>0</td>\n",
       "      <td>port authority guy by escalator (midtown)</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>[In, Porth, Authority, yesterday, around, 7, pm]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['yesterday', 'pm']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None, 'üåá']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None, 'üåá']</td>\n",
       "      <td>['üåá']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>https://newyork.craigslist.org/que/mis/d/far-r...</td>\n",
       "      <td>2024-06-24 06:17:00</td>\n",
       "      <td>\\nS&amp;J (FR)</td>\n",
       "      <td>40.6006</td>\n",
       "      <td>-73.7580</td>\n",
       "      <td>Wanted to point out that it s unimportant how ...</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>1900-01-01 06:17:00</td>\n",
       "      <td>0</td>\n",
       "      <td>s&amp;j (fr)</td>\n",
       "      <td>Queens</td>\n",
       "      <td>[Wanted, to, point, out, that, it, s, unimport...</td>\n",
       "      <td>['want', 'point', 's', 'say', 'live', 's', 'fa...</td>\n",
       "      <td>['time', 'move', 'past', 'benefit', 'attempt',...</td>\n",
       "      <td>['unimportant', 'many']</td>\n",
       "      <td>[None, None]</td>\n",
       "      <td>['‚åö', None, None, None, None, None, None, None...</td>\n",
       "      <td>[None, None, None, 'üí¨', None, None, None]</td>\n",
       "      <td>[None, None, None, None, None, 'üí¨', None, None...</td>\n",
       "      <td>['üí¨', '‚åö']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                                url  \\\n",
       "34          34  https://newyork.craigslist.org/mnh/mis/d/new-y...   \n",
       "35          35  https://newyork.craigslist.org/que/mis/d/far-r...   \n",
       "\n",
       "                   date                                         title  \\\n",
       "34  2024-06-24 10:59:00  \\nPort Authority guy by escalator (Midtown)    \n",
       "35  2024-06-24 06:17:00                                   \\nS&J (FR)    \n",
       "\n",
       "        lat      lng                                               post  \\\n",
       "34  40.7547 -73.9925            In Porth Authority yesterday around 7pm   \n",
       "35  40.6006 -73.7580  Wanted to point out that it s unimportant how ...   \n",
       "\n",
       "          Date                 Time  Weekday  \\\n",
       "34  2024-06-24  1900-01-01 10:59:00        0   \n",
       "35  2024-06-24  1900-01-01 06:17:00        0   \n",
       "\n",
       "                                  title_clean    borough  \\\n",
       "34  port authority guy by escalator (midtown)  Manhattan   \n",
       "35                                   s&j (fr)     Queens   \n",
       "\n",
       "                                       tokenized_post  \\\n",
       "34   [In, Porth, Authority, yesterday, around, 7, pm]   \n",
       "35  [Wanted, to, point, out, that, it, s, unimport...   \n",
       "\n",
       "                                                 verb  \\\n",
       "34                                                 []   \n",
       "35  ['want', 'point', 's', 'say', 'live', 's', 'fa...   \n",
       "\n",
       "                                                 noun  \\\n",
       "34                                ['yesterday', 'pm']   \n",
       "35  ['time', 'move', 'past', 'benefit', 'attempt',...   \n",
       "\n",
       "                        adj    emojis_adj  \\\n",
       "34                       []            []   \n",
       "35  ['unimportant', 'many']  [None, None]   \n",
       "\n",
       "                                          emojis_noun  \\\n",
       "34                                        [None, 'üåá']   \n",
       "35  ['‚åö', None, None, None, None, None, None, None...   \n",
       "\n",
       "                                  emojis_verb  \\\n",
       "34                                         []   \n",
       "35  [None, None, None, 'üí¨', None, None, None]   \n",
       "\n",
       "                                               emojis cleaned_emojis  \n",
       "34                                        [None, 'üåá']          ['üåá']  \n",
       "35  [None, None, None, None, None, 'üí¨', None, None...     ['üí¨', '‚åö']  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('public/data/mc_final_w_emojis.csv', sep='\\t')\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "35448b82-c50d-4617-939b-806f2df85e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>post</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>borough</th>\n",
       "      <th>tokenized_post</th>\n",
       "      <th>verb</th>\n",
       "      <th>noun</th>\n",
       "      <th>adj</th>\n",
       "      <th>emojis_adj</th>\n",
       "      <th>emojis_noun</th>\n",
       "      <th>emojis_verb</th>\n",
       "      <th>emojis</th>\n",
       "      <th>cleaned_emojis</th>\n",
       "      <th>Hour</th>\n",
       "      <th>session</th>\n",
       "      <th>post_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>https://newyork.craigslist.org/mnh/mis/d/new-y...</td>\n",
       "      <td>2024-06-07 08:24:00</td>\n",
       "      <td>\\nGuy Qtrain 86/2nd - lost contact</td>\n",
       "      <td>40.791584</td>\n",
       "      <td>-73.940392</td>\n",
       "      <td>We met on 86 2nd Q train late I was the olderg...</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>1900-01-01 08:24:00</td>\n",
       "      <td>4</td>\n",
       "      <td>guy qtrain 86/2nd - lost contact</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>[We, met, on, 86, 2nd, Q, train, late, I, was,...</td>\n",
       "      <td>['meet', 'go', 'lose', 'contact']</td>\n",
       "      <td>['train', 'guy', 'latinoblatino', 'guy', 'plac...</td>\n",
       "      <td>['2nd', 'oldergenwhite', 'interested']</td>\n",
       "      <td>[None, None, None]</td>\n",
       "      <td>['üöÜ', 'üë®', None, 'üë®', None, 'üî¢', None]</td>\n",
       "      <td>['ü§ù', '‚û°Ô∏è', None, 'üì±']</td>\n",
       "      <td>[None, None, None, 'ü§ù', '‚û°Ô∏è', None, 'üì±', 'üöÜ', ...</td>\n",
       "      <td>['ü§ù', '‚û°Ô∏è', 'üì±', 'üöÜ', 'üë®', 'üë®', 'üî¢']</td>\n",
       "      <td>8</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>https://newyork.craigslist.org/brk/mis/d/brook...</td>\n",
       "      <td>2024-06-27 15:23:00</td>\n",
       "      <td>\\nSoccer chick (Brooklyn)</td>\n",
       "      <td>40.646700</td>\n",
       "      <td>-73.957000</td>\n",
       "      <td>Soccer chick in black and white shoes we pract...</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>1900-01-01 15:23:00</td>\n",
       "      <td>3</td>\n",
       "      <td>soccer chick (brooklyn)</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>[Soccer, chick, in, black, and, white, shoes, ...</td>\n",
       "      <td>['practice', 'get', 'd', 'like', 'practice']</td>\n",
       "      <td>['soccer', 'chick', 'shoe', 'lil', 'bit', 'was...</td>\n",
       "      <td>['black', 'white', 'able']</td>\n",
       "      <td>['‚ö´', '‚ö™', None]</td>\n",
       "      <td>[None, None, None, None, None, None, None, 'üî¢'...</td>\n",
       "      <td>[None, None, None, 'üëç', None]</td>\n",
       "      <td>['‚ö´', '‚ö™', None, None, None, None, 'üëç', None, ...</td>\n",
       "      <td>['‚ö´', '‚ö™', 'üëç', 'üî¢']</td>\n",
       "      <td>15</td>\n",
       "      <td>Noon</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                url  \\\n",
       "170         170  https://newyork.craigslist.org/mnh/mis/d/new-y...   \n",
       "181         181  https://newyork.craigslist.org/brk/mis/d/brook...   \n",
       "\n",
       "                   date                                title        lat  \\\n",
       "170 2024-06-07 08:24:00  \\nGuy Qtrain 86/2nd - lost contact   40.791584   \n",
       "181 2024-06-27 15:23:00           \\nSoccer chick (Brooklyn)   40.646700   \n",
       "\n",
       "           lng                                               post        Date  \\\n",
       "170 -73.940392  We met on 86 2nd Q train late I was the olderg...  2024-06-07   \n",
       "181 -73.957000  Soccer chick in black and white shoes we pract...  2024-06-27   \n",
       "\n",
       "                    Time  Weekday                       title_clean  \\\n",
       "170  1900-01-01 08:24:00        4  guy qtrain 86/2nd - lost contact   \n",
       "181  1900-01-01 15:23:00        3           soccer chick (brooklyn)   \n",
       "\n",
       "       borough                                     tokenized_post  \\\n",
       "170  Manhattan  [We, met, on, 86, 2nd, Q, train, late, I, was,...   \n",
       "181   Brooklyn  [Soccer, chick, in, black, and, white, shoes, ...   \n",
       "\n",
       "                                             verb  \\\n",
       "170             ['meet', 'go', 'lose', 'contact']   \n",
       "181  ['practice', 'get', 'd', 'like', 'practice']   \n",
       "\n",
       "                                                  noun  \\\n",
       "170  ['train', 'guy', 'latinoblatino', 'guy', 'plac...   \n",
       "181  ['soccer', 'chick', 'shoe', 'lil', 'bit', 'was...   \n",
       "\n",
       "                                        adj          emojis_adj  \\\n",
       "170  ['2nd', 'oldergenwhite', 'interested']  [None, None, None]   \n",
       "181              ['black', 'white', 'able']    ['‚ö´', '‚ö™', None]   \n",
       "\n",
       "                                           emojis_noun  \\\n",
       "170             ['üöÜ', 'üë®', None, 'üë®', None, 'üî¢', None]   \n",
       "181  [None, None, None, None, None, None, None, 'üî¢'...   \n",
       "\n",
       "                       emojis_verb  \\\n",
       "170         ['ü§ù', '‚û°Ô∏è', None, 'üì±']   \n",
       "181  [None, None, None, 'üëç', None]   \n",
       "\n",
       "                                                emojis  \\\n",
       "170  [None, None, None, 'ü§ù', '‚û°Ô∏è', None, 'üì±', 'üöÜ', ...   \n",
       "181  ['‚ö´', '‚ö™', None, None, None, None, 'üëç', None, ...   \n",
       "\n",
       "                           cleaned_emojis  Hour        session  post_length  \n",
       "170  ['ü§ù', '‚û°Ô∏è', 'üì±', 'üöÜ', 'üë®', 'üë®', 'üî¢']     8  Early Morning         43.0  \n",
       "181                  ['‚ö´', '‚ö™', 'üëç', 'üî¢']    15           Noon         31.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert time into labels\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['Hour'] = df['date'].dt.hour\n",
    "\n",
    "b = [0,4,8,12,16,20,24]\n",
    "l = ['Late Night', 'Early Morning','Morning','Noon','Late Afternoon','Night']\n",
    "df['session'] = pd.cut(df['Hour'], bins=b, labels=l, include_lowest=True)\n",
    "df['post_length'] = df['post'].str.split(\" \").str.len() + df['title_clean'].str.split(\" \").str.len()\n",
    "# df.to_csv('test_final.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5610707d-f326-499d-ba06-b5e945c483d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>borough</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-30 23:47:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I was standing in line waiting for my curry we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-30 15:37:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I came in today Sunday with a black CROWN hat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-30 15:23:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I was the guy with the curly hair wearing all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-30 11:34:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-30 10:42:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Not sure what just happened but the site clinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-06-30 01:09:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You sat across from me You had on a black shir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-06-30 00:24:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We eyed one another throughout and both had th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-06-29 22:52:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You are the middle age man I stared outside of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-06-29 20:05:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Grungy shirt noticed your face more than your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-06-29 18:47:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were in a black t shirt black shorts white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-06-29 16:37:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>We both boarded the Huntington line train at J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-06-29 15:50:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>We talked about Giorgio moroder and Wilco unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-06-29 12:00:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We met on 86 2nd Q train late I was the olderg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-06-29 11:35:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Chilling in the park listening and feeling the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-06-29 03:59:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>friday night late my friends swore you cast so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-06-28 23:22:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were looking to plug your phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-06-28 15:43:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>You were cute gal in lime green dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-06-28 11:32:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>5 14 We both stopped to read a poem on the cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-06-27 23:49:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>I got on your bus at Madison and sat up front ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-06-27 23:31:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>Most beautiful Latina teller that works at Ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-06-27 20:56:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were sitting on the bench Funny thing is I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-06-27 20:03:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I am colombian You re Latino too We made out a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-06-27 16:36:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Outside the Stop and Shop on Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2024-06-27 07:54:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>Big blond hunk on a kids bike with butterfly h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-06-26 17:57:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I sat next to you at the uptown Q at Union Squ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-06-26 16:59:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I meant say something and I chickened out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-06-25 22:13:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>We were having a nice conversation Pero me des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-06-25 17:12:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>We had a conversation about Becky Chambers You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-06-25 12:37:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>do you ever check missed connections</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024-06-25 01:21:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>We met at the wedding and lost your number ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2024-06-24 21:28:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Hey I asked you for a pic of your tattoo You a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2024-06-24 20:36:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I saw you at the Greyhound bus stop in Provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024-06-24 18:42:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>I m polish guy rock climbing with favor to sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024-06-24 18:30:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were sitting with 2 older women 1 in a whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024-06-24 10:59:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>In Porth Authority yesterday around 7pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024-06-24 06:17:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Wanted to point out that it s unimportant how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-06-24 01:02:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I went to Public Records later on Friday nite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024-06-23 20:57:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024-06-23 20:53:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were sitting at the bar wearing all black ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024-06-23 19:36:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>At the supermarket cashing out you male buying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2024-06-23 18:53:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>we just had a cute little eye contact moment a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2024-06-23 17:45:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>After seeing all of the beautiful braless wome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-06-23 16:58:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were wearing those 5 toe shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2024-06-23 16:36:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>For the woman dressed in white I met in the va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2024-06-23 08:26:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You really liked to look of my big belly and I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2024-06-23 01:53:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>i lost your contact id like to meet up im free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2024-06-23 00:50:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were seated in the back corner I believe y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2024-06-22 18:08:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>On Saturday June 22nd at around 3 30 to 4 15 P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2024-06-22 16:51:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>the most beautiful girl I ve ever seen cute smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2024-06-22 09:40:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>just a quick note to say that i really enjoyed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2024-06-21 10:49:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We met Thursday evening 6 20 briefly as we wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2024-06-21 09:11:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Good morning happy Friday 40 year old male fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2024-06-21 01:52:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I switched wagons and sat next to a Guy there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2024-06-21 00:46:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>A woman who was on the train to Babylon in a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2024-06-20 21:12:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Sunday Russian speaking lady with an older couple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2024-06-20 20:59:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Russian speaking lady with an older couple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2024-06-20 17:44:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Waiting in line at cashier you behind me in li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2024-06-20 16:10:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We didnt even make eye contact but you are one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2024-06-20 15:12:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Loooking for stunning lady I seen on Wednesday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2024-06-20 14:04:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Pretty sure you noticed my eyes locked onto yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2024-06-20 10:50:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>LOOOOONNGGGG shot You were wearing a black bik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2024-06-19 22:38:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were the rather beefy office supplies truc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2024-06-19 19:58:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Is your hat one of these new AI company logos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2024-06-19 19:49:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Brief encounter yesterday late afternoon in Ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2024-06-19 19:23:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were with your white friend but ended up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2024-06-19 19:13:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Guy wearing grey pants touching his bulge on 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2024-06-19 16:32:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Me girl with curly hair and tie dye outfit You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2024-06-19 13:24:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>I m looking for this black beauty with the bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2024-06-19 11:49:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You couldn t keep your eyes off my bulge We ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2024-06-19 10:14:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>The couple of times I ve seen you we find ours...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2024-06-19 09:33:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We met at Max fish we dated for a few months w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2024-06-19 09:11:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>We spoke in the parking lot and I felt a conne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2024-06-18 17:54:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>We met at a bar on 5th av We clicked we were i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2024-06-18 15:00:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We were on the Q train uptown you are a beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2024-06-18 13:37:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>On 4th street Key food you were the guy at del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2024-06-18 11:47:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I was sitting on a bench writing in a notebook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2024-06-18 08:47:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I m a dude and see you there often having lunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2024-06-18 00:46:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I wish I d thought to say can I walk out with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2024-06-18 00:11:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Young fit male looking for first experience wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2024-06-17 22:53:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We chatted at Nowhere on Saturday You work in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2024-06-17 18:03:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>ou were straight curious and used to stop by m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2024-06-17 14:44:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>We are both men around the same age and we mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2024-06-17 11:57:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>sunday night june 15 south bound we made eye c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2024-06-17 11:39:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Really hope you for some reason check the miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2024-06-17 10:13:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Caught you twice as we ran by each other you i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2024-06-17 03:15:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>You are a very handsome guy with nice arms You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2024-06-17 00:01:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We were both eating pizza in Village Pizza in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2024-06-16 22:54:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I m not sure if this will work but I ve been k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2024-06-16 15:15:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>It s me from that strange magic show in April ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2024-06-15 23:28:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We met on the M train you asked me for gum and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2024-06-15 18:12:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were on a bench and I was in the train aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2024-06-15 17:43:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were this gorgeous asian lady that i saw o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2024-06-15 12:27:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>I was so focused on getting what I was getting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2024-06-15 10:32:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Searching for the good friend I met years ago ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2024-06-15 01:49:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2024-06-14 22:40:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>I was walking last week and was looking at men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2024-06-14 20:47:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Three weeks ago I was dog sitting my friend s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2024-06-14 12:18:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Hola soy marica Tengo hambre Quiero guevo Solo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024-06-14 09:06:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>I host only Looking for a top bunk man to come...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2024-06-14 00:30:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2024-06-14 00:05:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I male was standing in front of the coffee sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2024-06-13 20:43:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>June 13th 8 13 PM You stopped at the intersect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2024-06-13 20:36:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>In pink shirt jean shorts basketball shoes Wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2024-06-13 15:28:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I posted a similar message before this one so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2024-06-12 17:48:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hey so yes I saw you across from me on the Hun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2024-06-12 14:04:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We were both in the Q train we got off in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2024-06-12 09:58:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>You got on the train this morning I believe at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2024-06-12 07:25:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Maybe it was the wrong approach tried the Excu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2024-06-11 23:27:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We crossed paths on Saturday afternoon as my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2024-06-11 21:42:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>We arrived to look at an apartment at the same...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2024-06-11 21:20:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You drove the F train into West 4th today arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2024-06-11 21:08:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>This was a few months ago but I keep thinking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2024-06-11 16:55:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Downtown 6 train at 59th You and I were on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2024-06-11 16:41:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Aphrodite your waist to hip ratio is ridiculou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2024-06-11 12:59:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>We exchanged a glance as you were crossing 9th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2024-06-10 18:46:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Earlier this afternoon I saw you at the Barnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2024-06-10 18:07:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>you sat across from me you were wearing work b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2024-06-10 14:26:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>You tall guy beard blue eyes red notebook You ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2024-06-10 10:59:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were a tall girl in a miniskirt long dark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2024-06-09 21:52:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I was walking out as you were walking in You w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2024-06-09 21:33:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were walking on the Coney Island bound pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2024-06-09 16:43:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I am a young black female looking for the nice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2024-06-09 15:34:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were stopped in the bike lane I stopped an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2024-06-08 23:03:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were drafting wedding invites for your eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2024-06-08 18:46:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2024-06-08 17:37:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>How do you know when a woman is into women loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2024-06-08 10:28:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I had a lovely time chatting with you as we cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2024-06-08 02:49:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Hi I hope you re doing well if you re reading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2024-06-08 02:38:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>we were chatting on feeld and I thought our co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2024-06-08 01:45:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We shared an Uber going uptown You are an Ivy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2024-06-07 23:30:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Traded heys and backward glances as we passed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2024-06-07 15:24:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were the cute guy from Connecticut at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2024-06-07 14:52:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I thought you were someone I talk to on Fetlif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2024-06-07 11:57:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Lincoln Center New York Philharmonic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2024-06-07 08:25:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>Just moved to Riverdale a few months ago Looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2024-06-07 07:48:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Good day to all I was on the express bus in se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2024-06-06 19:07:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I asked you about all the running around you d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2024-06-06 15:39:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Thought I d throw this out there Thought you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2024-06-06 02:11:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>what would ve been in 2 weeks 1 day is gnawing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2024-06-05 22:45:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Water on both our minds I guess when it rains ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2024-06-05 22:37:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>U felt that I hope you see this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2024-06-05 19:17:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>dear beautiful man on the L train in the white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2024-06-05 18:19:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Wednesday at like 5 30 from Delancey Essex ish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2024-06-05 17:42:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Hey we were on the 5 03 PM ferry going to St G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024-06-05 16:57:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I sat next to you last night around 8 30pm on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2024-06-05 16:06:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You flipped your hair as we made eye contact a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2024-06-05 09:45:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We chatted at dumbo house u guy from Guinea I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2024-06-04 23:30:00</td>\n",
       "      <td>The Bronx</td>\n",
       "      <td>This seems like a long shot but putting this o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2024-06-04 23:25:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Tuesday night you were standing there with fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2024-06-04 21:57:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2024-06-04 21:23:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>i caught you absolutely dominating the pool ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2024-06-04 20:06:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>you know who you are you were wearing a blue a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2024-06-04 18:25:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>You Always make my day when u pass by my Work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2024-06-04 14:50:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Fit German man running at Riverside Park looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2024-06-04 13:43:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Saturday afternoon My neck hurt and we started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2024-06-04 09:34:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Met you once Felt like there was a lot more to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2024-06-04 05:34:00</td>\n",
       "      <td>Queens</td>\n",
       "      <td>I should have helped you with your suitcase at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2024-06-03 18:45:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were a beautiful Asian girl who I kept sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2024-06-03 11:30:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>There was this guy roller blading up Vanderbil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2024-06-03 10:19:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>m4m we went to the McCarren Park after Animal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2024-06-03 09:32:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>You were the beautiful trans woman sitting at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2024-06-03 07:33:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I m a guy hoping to get together with guy that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2024-06-03 06:23:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You are just my type lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2024-06-01 12:12:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>33 6 foot 195 lbs of muscle Very healthy and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2024-06-01 00:26:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You wore black and white or cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2024-06-01 09:47:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were on 8th street we looked at easch other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2024-06-01 21:23:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>You were sitting in the corner two of your fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2024-06-02 09:43:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I was working a checkout shift and we talked a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2024-06-02 14:38:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I was in a taxi driving up Houston Street yest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2024-06-07 07:49:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Good day to all I was on the express bus in se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2024-06-07 08:24:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We met on 86 2nd Q train late I was the olderg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2024-06-18 14:26:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Normal guy looking for a buddy who s into expl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2024-06-18 18:10:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Girl on the platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2024-06-19 07:38:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>We work together I think you are hot I think y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2024-06-23 19:10:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Guy in Yankees hat riding the northeast region...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2024-06-23 23:27:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I m the white guy you talked to last week we t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2024-06-26 04:22:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>You were coming out of the true value hardware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2024-06-26 07:15:00</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Seen you a few times ur Asian hot female dress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2024-06-26 08:18:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>I saw you on J train with Nirvana live 1993 t ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2024-06-26 20:24:00</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>I wanted to help you out with your situation H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024-06-26 23:33:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>So a group of Bible beaters tried judging me b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2024-06-27 15:23:00</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Soccer chick in black and white shoes we pract...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date        borough  \\\n",
       "0   2024-06-30 23:47:00      Manhattan   \n",
       "1   2024-06-30 15:37:00      Manhattan   \n",
       "2   2024-06-30 15:23:00       Brooklyn   \n",
       "3   2024-06-30 11:34:00       Brooklyn   \n",
       "4   2024-06-30 10:42:00         Queens   \n",
       "5   2024-06-30 01:09:00       Brooklyn   \n",
       "6   2024-06-30 00:24:00      Manhattan   \n",
       "7   2024-06-29 22:52:00      Manhattan   \n",
       "8   2024-06-29 20:05:00       Brooklyn   \n",
       "9   2024-06-29 18:47:00      Manhattan   \n",
       "10  2024-06-29 16:37:00         Queens   \n",
       "11  2024-06-29 15:50:00       Brooklyn   \n",
       "12  2024-06-29 12:00:00      Manhattan   \n",
       "13  2024-06-29 11:35:00      Manhattan   \n",
       "14  2024-06-29 03:59:00       Brooklyn   \n",
       "15  2024-06-28 23:22:00      Manhattan   \n",
       "16  2024-06-28 15:43:00         Queens   \n",
       "17  2024-06-28 11:32:00      Manhattan   \n",
       "18  2024-06-27 23:49:00      The Bronx   \n",
       "19  2024-06-27 23:31:00      The Bronx   \n",
       "20  2024-06-27 20:56:00      Manhattan   \n",
       "21  2024-06-27 20:03:00      Manhattan   \n",
       "22  2024-06-27 16:36:00       Brooklyn   \n",
       "23  2024-06-27 07:54:00      The Bronx   \n",
       "24  2024-06-26 17:57:00      Manhattan   \n",
       "25  2024-06-26 16:59:00       Brooklyn   \n",
       "26  2024-06-25 22:13:00       Brooklyn   \n",
       "27  2024-06-25 17:12:00         Queens   \n",
       "28  2024-06-25 12:37:00         Queens   \n",
       "29  2024-06-25 01:21:00         Queens   \n",
       "30  2024-06-24 21:28:00         Queens   \n",
       "31  2024-06-24 20:36:00      Manhattan   \n",
       "32  2024-06-24 18:42:00         Queens   \n",
       "33  2024-06-24 18:30:00       Brooklyn   \n",
       "34  2024-06-24 10:59:00      Manhattan   \n",
       "35  2024-06-24 06:17:00         Queens   \n",
       "36  2024-06-24 01:02:00       Brooklyn   \n",
       "37  2024-06-23 20:57:00       Brooklyn   \n",
       "38  2024-06-23 20:53:00       Brooklyn   \n",
       "39  2024-06-23 19:36:00      Manhattan   \n",
       "40  2024-06-23 18:53:00       Brooklyn   \n",
       "41  2024-06-23 17:45:00       Brooklyn   \n",
       "42  2024-06-23 16:58:00       Brooklyn   \n",
       "43  2024-06-23 16:36:00  Staten Island   \n",
       "44  2024-06-23 08:26:00      Manhattan   \n",
       "45  2024-06-23 01:53:00  Staten Island   \n",
       "46  2024-06-23 00:50:00       Brooklyn   \n",
       "47  2024-06-22 18:08:00      The Bronx   \n",
       "48  2024-06-22 16:51:00         Queens   \n",
       "49  2024-06-22 09:40:00      Manhattan   \n",
       "50  2024-06-21 10:49:00      Manhattan   \n",
       "51  2024-06-21 09:11:00      Manhattan   \n",
       "52  2024-06-21 01:52:00      Manhattan   \n",
       "53  2024-06-21 00:46:00      Manhattan   \n",
       "54  2024-06-20 21:12:00      Manhattan   \n",
       "55  2024-06-20 20:59:00      Manhattan   \n",
       "56  2024-06-20 17:44:00      Manhattan   \n",
       "57  2024-06-20 16:10:00      Manhattan   \n",
       "58  2024-06-20 15:12:00      Manhattan   \n",
       "59  2024-06-20 14:04:00       Brooklyn   \n",
       "60  2024-06-20 10:50:00       Brooklyn   \n",
       "61  2024-06-19 22:38:00      Manhattan   \n",
       "62  2024-06-19 19:58:00       Brooklyn   \n",
       "63  2024-06-19 19:49:00      Manhattan   \n",
       "64  2024-06-19 19:23:00      Manhattan   \n",
       "65  2024-06-19 19:13:00      Manhattan   \n",
       "66  2024-06-19 16:32:00       Brooklyn   \n",
       "67  2024-06-19 13:24:00      The Bronx   \n",
       "68  2024-06-19 11:49:00      Manhattan   \n",
       "69  2024-06-19 10:14:00      Manhattan   \n",
       "70  2024-06-19 09:33:00      Manhattan   \n",
       "71  2024-06-19 09:11:00  Staten Island   \n",
       "72  2024-06-18 17:54:00       Brooklyn   \n",
       "73  2024-06-18 15:00:00      Manhattan   \n",
       "74  2024-06-18 13:37:00      Manhattan   \n",
       "75  2024-06-18 11:47:00      Manhattan   \n",
       "76  2024-06-18 08:47:00      Manhattan   \n",
       "77  2024-06-18 00:46:00      Manhattan   \n",
       "78  2024-06-18 00:11:00       Brooklyn   \n",
       "79  2024-06-17 22:53:00      Manhattan   \n",
       "80  2024-06-17 18:03:00         Queens   \n",
       "81  2024-06-17 14:44:00         Queens   \n",
       "82  2024-06-17 11:57:00      Manhattan   \n",
       "83  2024-06-17 11:39:00      Manhattan   \n",
       "84  2024-06-17 10:13:00      Manhattan   \n",
       "85  2024-06-17 03:15:00      The Bronx   \n",
       "86  2024-06-17 00:01:00      Manhattan   \n",
       "87  2024-06-16 22:54:00      Manhattan   \n",
       "88  2024-06-16 15:15:00      Manhattan   \n",
       "89  2024-06-15 23:28:00      Manhattan   \n",
       "90  2024-06-15 18:12:00       Brooklyn   \n",
       "91  2024-06-15 17:43:00      Manhattan   \n",
       "92  2024-06-15 12:27:00      The Bronx   \n",
       "93  2024-06-15 10:32:00         Queens   \n",
       "94  2024-06-15 01:49:00      Manhattan   \n",
       "95  2024-06-14 22:40:00         Queens   \n",
       "96  2024-06-14 20:47:00      Manhattan   \n",
       "97  2024-06-14 12:18:00         Queens   \n",
       "98  2024-06-14 09:06:00         Queens   \n",
       "99  2024-06-14 00:30:00       Brooklyn   \n",
       "100 2024-06-14 00:05:00       Brooklyn   \n",
       "101 2024-06-13 20:43:00         Queens   \n",
       "102 2024-06-13 20:36:00      Manhattan   \n",
       "103 2024-06-13 15:28:00       Brooklyn   \n",
       "104 2024-06-12 17:48:00      Manhattan   \n",
       "105 2024-06-12 14:04:00      Manhattan   \n",
       "106 2024-06-12 09:58:00      The Bronx   \n",
       "107 2024-06-12 07:25:00  Staten Island   \n",
       "108 2024-06-11 23:27:00      Manhattan   \n",
       "109 2024-06-11 21:42:00       Brooklyn   \n",
       "110 2024-06-11 21:20:00      Manhattan   \n",
       "111 2024-06-11 21:08:00      Manhattan   \n",
       "112 2024-06-11 16:55:00      Manhattan   \n",
       "113 2024-06-11 16:41:00      Manhattan   \n",
       "114 2024-06-11 12:59:00       Brooklyn   \n",
       "115 2024-06-10 18:46:00       Brooklyn   \n",
       "116 2024-06-10 18:07:00       Brooklyn   \n",
       "117 2024-06-10 14:26:00         Queens   \n",
       "118 2024-06-10 10:59:00      Manhattan   \n",
       "119 2024-06-09 21:52:00       Brooklyn   \n",
       "120 2024-06-09 21:33:00       Brooklyn   \n",
       "121 2024-06-09 16:43:00      Manhattan   \n",
       "122 2024-06-09 15:34:00       Brooklyn   \n",
       "123 2024-06-08 23:03:00       Brooklyn   \n",
       "124 2024-06-08 18:46:00       Brooklyn   \n",
       "125 2024-06-08 17:37:00      Manhattan   \n",
       "126 2024-06-08 10:28:00      Manhattan   \n",
       "127 2024-06-08 02:49:00       Brooklyn   \n",
       "128 2024-06-08 02:38:00       Brooklyn   \n",
       "129 2024-06-08 01:45:00      Manhattan   \n",
       "130 2024-06-07 23:30:00      Manhattan   \n",
       "131 2024-06-07 15:24:00      Manhattan   \n",
       "132 2024-06-07 14:52:00      Manhattan   \n",
       "133 2024-06-07 11:57:00      Manhattan   \n",
       "134 2024-06-07 08:25:00      The Bronx   \n",
       "135 2024-06-07 07:48:00  Staten Island   \n",
       "136 2024-06-06 19:07:00      Manhattan   \n",
       "137 2024-06-06 15:39:00         Queens   \n",
       "138 2024-06-06 02:11:00      Manhattan   \n",
       "139 2024-06-05 22:45:00      Manhattan   \n",
       "140 2024-06-05 22:37:00       Brooklyn   \n",
       "141 2024-06-05 19:17:00      Manhattan   \n",
       "142 2024-06-05 18:19:00         Queens   \n",
       "143 2024-06-05 17:42:00  Staten Island   \n",
       "144 2024-06-05 16:57:00       Brooklyn   \n",
       "145 2024-06-05 16:06:00      Manhattan   \n",
       "146 2024-06-05 09:45:00      Manhattan   \n",
       "147 2024-06-04 23:30:00      The Bronx   \n",
       "148 2024-06-04 23:25:00       Brooklyn   \n",
       "149 2024-06-04 21:57:00      Manhattan   \n",
       "150 2024-06-04 21:23:00         Queens   \n",
       "151 2024-06-04 20:06:00       Brooklyn   \n",
       "152 2024-06-04 18:25:00         Queens   \n",
       "153 2024-06-04 14:50:00      Manhattan   \n",
       "154 2024-06-04 13:43:00      Manhattan   \n",
       "155 2024-06-04 09:34:00       Brooklyn   \n",
       "156 2024-06-04 05:34:00         Queens   \n",
       "157 2024-06-03 18:45:00      Manhattan   \n",
       "158 2024-06-03 11:30:00       Brooklyn   \n",
       "159 2024-06-03 10:19:00       Brooklyn   \n",
       "160 2024-06-03 09:32:00  Staten Island   \n",
       "161 2024-06-03 07:33:00      Manhattan   \n",
       "162 2024-06-03 06:23:00       Brooklyn   \n",
       "163 2024-06-01 12:12:00       Brooklyn   \n",
       "164 2024-06-01 00:26:00      Manhattan   \n",
       "165 2024-06-01 09:47:00      Manhattan   \n",
       "166 2024-06-01 21:23:00       Brooklyn   \n",
       "167 2024-06-02 09:43:00       Brooklyn   \n",
       "168 2024-06-02 14:38:00      Manhattan   \n",
       "169 2024-06-07 07:49:00      Manhattan   \n",
       "170 2024-06-07 08:24:00      Manhattan   \n",
       "171 2024-06-18 14:26:00      Manhattan   \n",
       "172 2024-06-18 18:10:00      Manhattan   \n",
       "173 2024-06-19 07:38:00      Manhattan   \n",
       "174 2024-06-23 19:10:00      Manhattan   \n",
       "175 2024-06-23 23:27:00      Manhattan   \n",
       "176 2024-06-26 04:22:00      Manhattan   \n",
       "177 2024-06-26 07:15:00  Staten Island   \n",
       "178 2024-06-26 08:18:00       Brooklyn   \n",
       "179 2024-06-26 20:24:00      Manhattan   \n",
       "180 2024-06-26 23:33:00       Brooklyn   \n",
       "181 2024-06-27 15:23:00       Brooklyn   \n",
       "\n",
       "                                                  post  \n",
       "0    I was standing in line waiting for my curry we...  \n",
       "1    I came in today Sunday with a black CROWN hat ...  \n",
       "2    I was the guy with the curly hair wearing all ...  \n",
       "3                                                   Hi  \n",
       "4    Not sure what just happened but the site clinc...  \n",
       "5    You sat across from me You had on a black shir...  \n",
       "6    We eyed one another throughout and both had th...  \n",
       "7    You are the middle age man I stared outside of...  \n",
       "8    Grungy shirt noticed your face more than your ...  \n",
       "9    You were in a black t shirt black shorts white...  \n",
       "10   We both boarded the Huntington line train at J...  \n",
       "11   We talked about Giorgio moroder and Wilco unde...  \n",
       "12   We met on 86 2nd Q train late I was the olderg...  \n",
       "13   Chilling in the park listening and feeling the...  \n",
       "14   friday night late my friends swore you cast so...  \n",
       "15                 You were looking to plug your phone  \n",
       "16               You were cute gal in lime green dress  \n",
       "17   5 14 We both stopped to read a poem on the cor...  \n",
       "18   I got on your bus at Madison and sat up front ...  \n",
       "19   Most beautiful Latina teller that works at Ban...  \n",
       "20   You were sitting on the bench Funny thing is I...  \n",
       "21   I am colombian You re Latino too We made out a...  \n",
       "22               Outside the Stop and Shop on Atlantic  \n",
       "23   Big blond hunk on a kids bike with butterfly h...  \n",
       "24   I sat next to you at the uptown Q at Union Squ...  \n",
       "25           I meant say something and I chickened out  \n",
       "26   We were having a nice conversation Pero me des...  \n",
       "27   We had a conversation about Becky Chambers You...  \n",
       "28                do you ever check missed connections  \n",
       "29   We met at the wedding and lost your number ple...  \n",
       "30   Hey I asked you for a pic of your tattoo You a...  \n",
       "31   I saw you at the Greyhound bus stop in Provide...  \n",
       "32   I m polish guy rock climbing with favor to sha...  \n",
       "33   You were sitting with 2 older women 1 in a whe...  \n",
       "34             In Porth Authority yesterday around 7pm  \n",
       "35   Wanted to point out that it s unimportant how ...  \n",
       "36   I went to Public Records later on Friday nite ...  \n",
       "37                                                 NaN  \n",
       "38   You were sitting at the bar wearing all black ...  \n",
       "39   At the supermarket cashing out you male buying...  \n",
       "40   we just had a cute little eye contact moment a...  \n",
       "41   After seeing all of the beautiful braless wome...  \n",
       "42                  You were wearing those 5 toe shoes  \n",
       "43   For the woman dressed in white I met in the va...  \n",
       "44   You really liked to look of my big belly and I...  \n",
       "45   i lost your contact id like to meet up im free...  \n",
       "46   You were seated in the back corner I believe y...  \n",
       "47   On Saturday June 22nd at around 3 30 to 4 15 P...  \n",
       "48   the most beautiful girl I ve ever seen cute smile  \n",
       "49   just a quick note to say that i really enjoyed...  \n",
       "50   We met Thursday evening 6 20 briefly as we wer...  \n",
       "51   Good morning happy Friday 40 year old male fro...  \n",
       "52   I switched wagons and sat next to a Guy there ...  \n",
       "53   A woman who was on the train to Babylon in a b...  \n",
       "54   Sunday Russian speaking lady with an older couple  \n",
       "55          Russian speaking lady with an older couple  \n",
       "56   Waiting in line at cashier you behind me in li...  \n",
       "57   We didnt even make eye contact but you are one...  \n",
       "58   Loooking for stunning lady I seen on Wednesday...  \n",
       "59   Pretty sure you noticed my eyes locked onto yo...  \n",
       "60   LOOOOONNGGGG shot You were wearing a black bik...  \n",
       "61   You were the rather beefy office supplies truc...  \n",
       "62   Is your hat one of these new AI company logos ...  \n",
       "63   Brief encounter yesterday late afternoon in Ri...  \n",
       "64   You were with your white friend but ended up t...  \n",
       "65   Guy wearing grey pants touching his bulge on 2...  \n",
       "66   Me girl with curly hair and tie dye outfit You...  \n",
       "67   I m looking for this black beauty with the bea...  \n",
       "68   You couldn t keep your eyes off my bulge We ma...  \n",
       "69   The couple of times I ve seen you we find ours...  \n",
       "70   We met at Max fish we dated for a few months w...  \n",
       "71   We spoke in the parking lot and I felt a conne...  \n",
       "72   We met at a bar on 5th av We clicked we were i...  \n",
       "73   We were on the Q train uptown you are a beauti...  \n",
       "74   On 4th street Key food you were the guy at del...  \n",
       "75   I was sitting on a bench writing in a notebook...  \n",
       "76   I m a dude and see you there often having lunc...  \n",
       "77   I wish I d thought to say can I walk out with ...  \n",
       "78   Young fit male looking for first experience wi...  \n",
       "79   We chatted at Nowhere on Saturday You work in ...  \n",
       "80   ou were straight curious and used to stop by m...  \n",
       "81   We are both men around the same age and we mad...  \n",
       "82   sunday night june 15 south bound we made eye c...  \n",
       "83   Really hope you for some reason check the miss...  \n",
       "84   Caught you twice as we ran by each other you i...  \n",
       "85   You are a very handsome guy with nice arms You...  \n",
       "86   We were both eating pizza in Village Pizza in ...  \n",
       "87   I m not sure if this will work but I ve been k...  \n",
       "88   It s me from that strange magic show in April ...  \n",
       "89   We met on the M train you asked me for gum and...  \n",
       "90   You were on a bench and I was in the train aro...  \n",
       "91   You were this gorgeous asian lady that i saw o...  \n",
       "92   I was so focused on getting what I was getting...  \n",
       "93   Searching for the good friend I met years ago ...  \n",
       "94                                                  Hi  \n",
       "95   I was walking last week and was looking at men...  \n",
       "96   Three weeks ago I was dog sitting my friend s ...  \n",
       "97   Hola soy marica Tengo hambre Quiero guevo Solo...  \n",
       "98   I host only Looking for a top bunk man to come...  \n",
       "99                                                   3  \n",
       "100  I male was standing in front of the coffee sho...  \n",
       "101  June 13th 8 13 PM You stopped at the intersect...  \n",
       "102  In pink shirt jean shorts basketball shoes Wit...  \n",
       "103  I posted a similar message before this one so ...  \n",
       "104  Hey so yes I saw you across from me on the Hun...  \n",
       "105  We were both in the Q train we got off in the ...  \n",
       "106  You got on the train this morning I believe at...  \n",
       "107  Maybe it was the wrong approach tried the Excu...  \n",
       "108  We crossed paths on Saturday afternoon as my f...  \n",
       "109  We arrived to look at an apartment at the same...  \n",
       "110  You drove the F train into West 4th today arou...  \n",
       "111  This was a few months ago but I keep thinking ...  \n",
       "112  Downtown 6 train at 59th You and I were on the...  \n",
       "113  Aphrodite your waist to hip ratio is ridiculou...  \n",
       "114  We exchanged a glance as you were crossing 9th...  \n",
       "115  Earlier this afternoon I saw you at the Barnes...  \n",
       "116  you sat across from me you were wearing work b...  \n",
       "117  You tall guy beard blue eyes red notebook You ...  \n",
       "118  You were a tall girl in a miniskirt long dark ...  \n",
       "119  I was walking out as you were walking in You w...  \n",
       "120  You were walking on the Coney Island bound pla...  \n",
       "121  I am a young black female looking for the nice...  \n",
       "122  You were stopped in the bike lane I stopped an...  \n",
       "123  You were drafting wedding invites for your eng...  \n",
       "124                                                NaN  \n",
       "125  How do you know when a woman is into women loc...  \n",
       "126  I had a lovely time chatting with you as we cr...  \n",
       "127  Hi I hope you re doing well if you re reading ...  \n",
       "128  we were chatting on feeld and I thought our co...  \n",
       "129  We shared an Uber going uptown You are an Ivy ...  \n",
       "130  Traded heys and backward glances as we passed ...  \n",
       "131  You were the cute guy from Connecticut at the ...  \n",
       "132  I thought you were someone I talk to on Fetlif...  \n",
       "133               Lincoln Center New York Philharmonic  \n",
       "134  Just moved to Riverdale a few months ago Looki...  \n",
       "135  Good day to all I was on the express bus in se...  \n",
       "136  I asked you about all the running around you d...  \n",
       "137  Thought I d throw this out there Thought you w...  \n",
       "138  what would ve been in 2 weeks 1 day is gnawing...  \n",
       "139  Water on both our minds I guess when it rains ...  \n",
       "140                    U felt that I hope you see this  \n",
       "141  dear beautiful man on the L train in the white...  \n",
       "142  Wednesday at like 5 30 from Delancey Essex ish...  \n",
       "143  Hey we were on the 5 03 PM ferry going to St G...  \n",
       "144  I sat next to you last night around 8 30pm on ...  \n",
       "145  You flipped your hair as we made eye contact a...  \n",
       "146  We chatted at dumbo house u guy from Guinea I ...  \n",
       "147  This seems like a long shot but putting this o...  \n",
       "148  Tuesday night you were standing there with fri...  \n",
       "149                                                NaN  \n",
       "150  i caught you absolutely dominating the pool ta...  \n",
       "151  you know who you are you were wearing a blue a...  \n",
       "152  You Always make my day when u pass by my Work ...  \n",
       "153  Fit German man running at Riverside Park looki...  \n",
       "154  Saturday afternoon My neck hurt and we started...  \n",
       "155  Met you once Felt like there was a lot more to...  \n",
       "156  I should have helped you with your suitcase at...  \n",
       "157  You were a beautiful Asian girl who I kept sta...  \n",
       "158  There was this guy roller blading up Vanderbil...  \n",
       "159  m4m we went to the McCarren Park after Animal ...  \n",
       "160  You were the beautiful trans woman sitting at ...  \n",
       "161  I m a guy hoping to get together with guy that...  \n",
       "162                           You are just my type lol  \n",
       "163  33 6 foot 195 lbs of muscle Very healthy and c...  \n",
       "164                  You wore black and white or cream  \n",
       "165    You were on 8th street we looked at easch other  \n",
       "166  You were sitting in the corner two of your fri...  \n",
       "167  I was working a checkout shift and we talked a...  \n",
       "168  I was in a taxi driving up Houston Street yest...  \n",
       "169  Good day to all I was on the express bus in se...  \n",
       "170  We met on 86 2nd Q train late I was the olderg...  \n",
       "171  Normal guy looking for a buddy who s into expl...  \n",
       "172                               Girl on the platform  \n",
       "173  We work together I think you are hot I think y...  \n",
       "174  Guy in Yankees hat riding the northeast region...  \n",
       "175  I m the white guy you talked to last week we t...  \n",
       "176  You were coming out of the true value hardware...  \n",
       "177  Seen you a few times ur Asian hot female dress...  \n",
       "178  I saw you on J train with Nirvana live 1993 t ...  \n",
       "179  I wanted to help you out with your situation H...  \n",
       "180  So a group of Bible beaters tried judging me b...  \n",
       "181  Soccer chick in black and white shoes we pract...  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['date', 'borough', 'post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10ef4c-55fe-492b-be7e-a02f1815d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many post mentioned train\n",
    "df['noun'] = df['noun'].apply(literal_eval)\n",
    "df_bk_exploded = df.explode('noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "00b5d379-7171-431c-8707-773a0f2e7d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: ['guy', 'hair', 'bit', 'name', 't', 'number', 'shot', 'vibe']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## nouns in brooklyn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_bk \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborough\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrooklyn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df_bk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_bk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(literal_eval)\n\u001b[1;32m      4\u001b[0m df_bk_exploded \u001b[38;5;241m=\u001b[39m df_bk\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# list(set(df_bk_exploded['noun']))\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:112\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:111\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:85\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:76\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 76\u001b[0m         _raise_malformed_node(node)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:73\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     72\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: ['guy', 'hair', 'bit', 'name', 't', 'number', 'shot', 'vibe']"
     ]
    }
   ],
   "source": [
    "## nouns in brooklyn\n",
    "df_bk = df[df['borough'] == \"Brooklyn\"]\n",
    "df_bk['noun'] = df_bk['noun'].apply(literal_eval)\n",
    "df_bk_exploded = df_bk.explode('noun')\n",
    "# list(set(df_bk_exploded['noun']))\n",
    "df_mh_exploded.value_counts('noun').head(10)\n",
    "\n",
    "# \n",
    "# df_bk_exploded.value_counts('noun')\n",
    "# df_bk_noun_exploded = df_bk_exploded.groupby(['session', 'noun']).size().reset_index(name='count')\n",
    "# # df_bk_noun_exploded\n",
    "# # noun_counts\n",
    "# value_counts_bk_nouns = df_bk_noun_exploded.groupby('session').apply(lambda x: x.nlargest(5, 'count')).reset_index(drop=True)\n",
    "# value_counts_bk_nouns\n",
    "\n",
    "\n",
    "# # Check if \"train\" is in the list of nouns for each post\n",
    "# df_bk['contains_train'] = df_bk['noun'].apply(lambda x: 'train' in x)\n",
    "\n",
    "# # Count the number of posts that contain \"train\"\n",
    "# train_count = df_bk['contains_train'].sum()\n",
    "\n",
    "# # Calculate the percentage\n",
    "# total_posts = len(df_bk)\n",
    "# percentage_train = (train_count / total_posts) * 100\n",
    "\n",
    "# print(f\"Percentage of posts that mention 'train': {percentage_train:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "55ceb002-a45e-427f-8665-b35abecd2360",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: ['line', 'curry', 'conversation', 'eye', 'skin', 'face']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## nouns in brooklyn\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df_mh \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mborough\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mManhattan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m df_mh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_mh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(literal_eval)\n\u001b[1;32m      4\u001b[0m df_mh_exploded \u001b[38;5;241m=\u001b[39m df_mh\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m df_mh_exploded\u001b[38;5;241m.\u001b[39mvalue_counts(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoun\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:112\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert(node_or_string)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:111\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:85\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _convert_num(node)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:76\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 76\u001b[0m         _raise_malformed_node(node)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ast.py:73\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     72\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: ['line', 'curry', 'conversation', 'eye', 'skin', 'face']"
     ]
    }
   ],
   "source": [
    "## nouns in brooklyn\n",
    "df_mh = df[df['borough'] == \"Manhattan\"]\n",
    "df_mh['noun'] = df_mh['noun'].apply(literal_eval)\n",
    "df_mh_exploded = df_mh.explode('noun')\n",
    "df_mh_exploded.value_counts('noun').head(10)\n",
    "# df_mh_noun_exploded = df_mh_exploded.groupby(['session', 'noun']).size().reset_index(name='count')\n",
    "# # noun_counts\n",
    "# value_counts_mh_nouns = df_mh_noun_exploded.groupby('session').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "# value_counts_mh_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c91013-0f8d-4cb5-b0ed-39fa2924a100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8d785e9f-07a4-46e5-8eff-c3c16189b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/1556758348.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_q['noun'] = df_q['noun'].apply(literal_eval)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "noun\n",
       "eye           6\n",
       "time          5\n",
       "smile         3\n",
       "contact       3\n",
       "train         3\n",
       "work          2\n",
       "man           2\n",
       "connection    2\n",
       "beat          2\n",
       "number        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nouns in Queens\n",
    "df_q = df[df['borough'] == \"Queens\"]\n",
    "df_q['noun'] = df_q['noun'].apply(literal_eval)\n",
    "df_q_exploded = df_q.explode('noun')\n",
    "df_q_exploded.value_counts('noun').head(10)\n",
    "# df_mh_noun_exploded = df_mh_exploded.groupby(['session', 'noun']).size().reset_index(name='count')\n",
    "# # noun_counts\n",
    "# value_counts_mh_nouns = df_mh_noun_exploded.groupby('session').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "# value_counts_mh_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7ffc723-d5c9-4c67-9bcd-9e79f5b7f9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/1870194257.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_b['noun'] = df_b['noun'].apply(literal_eval)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "noun\n",
       "guy        2\n",
       "train      2\n",
       "kit        2\n",
       "hair       2\n",
       "tee        2\n",
       "morning    2\n",
       "message    1\n",
       "park       1\n",
       "nail       1\n",
       "month      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nouns in the Bronx\n",
    "df_b = df[df['borough'] == \"The Bronx\"]\n",
    "df_b['noun'] = df_b['noun'].apply(literal_eval)\n",
    "df_b_exploded = df_b.explode('noun')\n",
    "df_b_exploded.value_counts('noun').head(10)\n",
    "# df_mh_noun_exploded = df_mh_exploded.groupby(['session', 'noun']).size().reset_index(name='count')\n",
    "# # noun_counts\n",
    "# value_counts_mh_nouns = df_mh_noun_exploded.groupby('session').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "# value_counts_mh_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "14b52146-6ebf-474a-a370-dda0e19931b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/2443392301.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_si['noun'] = df_si['noun'].apply(literal_eval)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "noun\n",
       "contact     3\n",
       "guy         3\n",
       "woman       2\n",
       "door        2\n",
       "beard       2\n",
       "bike        2\n",
       "approach    2\n",
       "pm          2\n",
       "time        2\n",
       "dress       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nouns in the Staten Island\n",
    "df_si = df[df['borough'] == \"Staten Island\"]\n",
    "df_si['noun'] = df_si['noun'].apply(literal_eval)\n",
    "df_si_exploded = df_si.explode('noun')\n",
    "df_si_exploded.value_counts('noun').head(10)\n",
    "# df_mh_noun_exploded = df_mh_exploded.groupby(['session', 'noun']).size().reset_index(name='count')\n",
    "# # noun_counts\n",
    "# value_counts_mh_nouns = df_mh_noun_exploded.groupby('session').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "# value_counts_mh_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efaa3525-1289-41b8-9bae-797eae6fc0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/1561343530.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_noun_borough['noun'] = df_noun_borough['noun'].apply(literal_eval)\n",
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/1561343530.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  value_counts = noun_counts.groupby('borough').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-c95dfe31d585411c89f0b08a58d0e44c.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-c95dfe31d585411c89f0b08a58d0e44c.vega-embed details,\n",
       "  #altair-viz-c95dfe31d585411c89f0b08a58d0e44c.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-c95dfe31d585411c89f0b08a58d0e44c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-c95dfe31d585411c89f0b08a58d0e44c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-c95dfe31d585411c89f0b08a58d0e44c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f14694e66d36bf4d2bf030e456af3cf7\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"borough\", \"type\": \"nominal\"}, \"column\": {\"field\": \"Weekday\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"noun\", \"type\": \"nominal\"}}, \"height\": 600, \"width\": 110, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-f14694e66d36bf4d2bf030e456af3cf7\": [{\"borough\": \"Brooklyn\", \"noun\": \"eye\", \"Weekday\": 6, \"count\": 4}, {\"borough\": \"Brooklyn\", \"noun\": \"friend\", \"Weekday\": 1, \"count\": 4}, {\"borough\": \"Brooklyn\", \"noun\": \"friend\", \"Weekday\": 5, \"count\": 4}, {\"borough\": \"Brooklyn\", \"noun\": \"hair\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"platform\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"shirt\", \"Weekday\": 5, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"t\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"train\", \"Weekday\": 5, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"woman\", \"Weekday\": 0, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"woman\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Manhattan\", \"noun\": \"eye\", \"Weekday\": 2, \"count\": 8}, {\"borough\": \"Manhattan\", \"noun\": \"guy\", \"Weekday\": 4, \"count\": 7}, {\"borough\": \"Manhattan\", \"noun\": \"train\", \"Weekday\": 1, \"count\": 5}, {\"borough\": \"Manhattan\", \"noun\": \"train\", \"Weekday\": 2, \"count\": 5}, {\"borough\": \"Manhattan\", \"noun\": \"train\", \"Weekday\": 5, \"count\": 5}, {\"borough\": \"Manhattan\", \"noun\": \"friend\", \"Weekday\": 0, \"count\": 4}, {\"borough\": \"Manhattan\", \"noun\": \"friend\", \"Weekday\": 4, \"count\": 4}, {\"borough\": \"Manhattan\", \"noun\": \"guy\", \"Weekday\": 2, \"count\": 4}, {\"borough\": \"Manhattan\", \"noun\": \"number\", \"Weekday\": 5, \"count\": 4}, {\"borough\": \"Manhattan\", \"noun\": \"bench\", \"Weekday\": 1, \"count\": 3}, {\"borough\": \"Queens\", \"noun\": \"time\", \"Weekday\": 0, \"count\": 5}, {\"borough\": \"Queens\", \"noun\": \"eye\", \"Weekday\": 0, \"count\": 3}, {\"borough\": \"Queens\", \"noun\": \"beat\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"connection\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"contact\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"guy\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"number\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"past\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"smile\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"train\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"guy\", \"Weekday\": 4, \"count\": 3}, {\"borough\": \"Staten Island\", \"noun\": \"approach\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"beard\", \"Weekday\": 4, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"bike\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"contact\", \"Weekday\": 6, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"parking\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"pm\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"time\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"4x\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"Staten Island\", \"noun\": \"bar\", \"Weekday\": 0, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"guy\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"kit\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"tee\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"22nd\", \"Weekday\": 5, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"35y\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"50am\", \"Weekday\": 0, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"86th\", \"Weekday\": 0, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"access\", \"Weekday\": 1, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"adventure\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"arm\", \"Weekday\": 0, \"count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noun_borough = df[['noun', 'borough', 'Weekday']]\n",
    "df_noun_borough['noun'] = df_noun_borough['noun'].apply(literal_eval)\n",
    "df_exploded = df_noun_borough.explode('noun')\n",
    "\n",
    "# # Group by 'borough' and get the value counts for 'nouns'\n",
    "noun_counts = df_exploded.groupby(['borough', 'noun', 'Weekday']).size().reset_index(name='count')\n",
    "# noun_counts\n",
    "value_counts = noun_counts.groupby('borough').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "\n",
    "\n",
    "alt.Chart(value_counts).mark_bar().encode(\n",
    "    y='noun',\n",
    "    x='count',\n",
    "    color='borough',\n",
    "    column='Weekday', \n",
    "    \n",
    ").properties(\n",
    "    width=110,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "## noun to replace t, tee, and shirt\n",
    "## normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634dde1e-d39f-4e1d-aca5-3e8deec49799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/717391953.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_noun_borough['noun'] = df_noun_borough['noun'].apply(literal_eval)\n",
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/717391953.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  noun_counts = df_exploded.groupby(['borough', 'noun', 'session', 'Weekday']).size().reset_index(name='count')\n",
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/717391953.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  value_counts = noun_counts.groupby('borough').apply(lambda x: x.nlargest(5, 'count')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b98f130f9292434b91dea8f35f9f4143.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b98f130f9292434b91dea8f35f9f4143.vega-embed details,\n",
       "  #altair-viz-b98f130f9292434b91dea8f35f9f4143.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b98f130f9292434b91dea8f35f9f4143\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b98f130f9292434b91dea8f35f9f4143\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b98f130f9292434b91dea8f35f9f4143\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a6262185d01823290e6cc6da6426f037\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"borough\", \"type\": \"nominal\"}, \"column\": {\"field\": \"session\", \"sort\": [\"Late Night\", \"Early Morning\", \"Morning\", \"Noon\", \"Late Afternoon\", \"Night\"], \"type\": \"ordinal\"}, \"row\": {\"field\": \"Weekday\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"noun\", \"type\": \"nominal\"}}, \"height\": 300, \"width\": 120, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-a6262185d01823290e6cc6da6426f037\": [{\"borough\": \"Brooklyn\", \"noun\": \"friend\", \"session\": \"Night\", \"Weekday\": 1, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"t\", \"session\": \"Noon\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Brooklyn\", \"noun\": \"apartment\", \"session\": \"Night\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Brooklyn\", \"noun\": \"book\", \"session\": \"Night\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"Brooklyn\", \"noun\": \"chat\", \"session\": \"Late Night\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"Manhattan\", \"noun\": \"eye\", \"session\": \"Late Afternoon\", \"Weekday\": 2, \"count\": 5}, {\"borough\": \"Manhattan\", \"noun\": \"guy\", \"session\": \"Early Morning\", \"Weekday\": 4, \"count\": 5}, {\"borough\": \"Manhattan\", \"noun\": \"train\", \"session\": \"Noon\", \"Weekday\": 1, \"count\": 4}, {\"borough\": \"Manhattan\", \"noun\": \"bench\", \"session\": \"Morning\", \"Weekday\": 1, \"count\": 3}, {\"borough\": \"Manhattan\", \"noun\": \"dog\", \"session\": \"Late Afternoon\", \"Weekday\": 4, \"count\": 3}, {\"borough\": \"Queens\", \"noun\": \"eye\", \"session\": \"Noon\", \"Weekday\": 0, \"count\": 3}, {\"borough\": \"Queens\", \"noun\": \"beat\", \"session\": \"Night\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"contact\", \"session\": \"Noon\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"past\", \"session\": \"Early Morning\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"noun\": \"time\", \"session\": \"Noon\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"guy\", \"session\": \"Early Morning\", \"Weekday\": 4, \"count\": 3}, {\"borough\": \"Staten Island\", \"noun\": \"approach\", \"session\": \"Early Morning\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"beard\", \"session\": \"Early Morning\", \"Weekday\": 4, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"bike\", \"session\": \"Late Afternoon\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"noun\": \"contact\", \"session\": \"Late Night\", \"Weekday\": 6, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"guy\", \"session\": \"Late Night\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"kit\", \"session\": \"Night\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"tee\", \"session\": \"Morning\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"The Bronx\", \"noun\": \"22nd\", \"session\": \"Late Afternoon\", \"Weekday\": 5, \"count\": 1}, {\"borough\": \"The Bronx\", \"noun\": \"35y\", \"session\": \"Early Morning\", \"Weekday\": 4, \"count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### why is this chart off? \n",
    "\n",
    "df_noun_borough = df[['noun', 'borough', 'session', 'Weekday']]\n",
    "df_noun_borough['noun'] = df_noun_borough['noun'].apply(literal_eval)\n",
    "df_exploded = df_noun_borough.explode('noun')\n",
    "\n",
    "# # Group by 'borough' and get the value counts for 'nouns'\n",
    "noun_counts = df_exploded.groupby(['borough', 'noun', 'session', 'Weekday']).size().reset_index(name='count')\n",
    "# noun_counts\n",
    "value_counts = noun_counts.groupby('borough').apply(lambda x: x.nlargest(5, 'count')).reset_index(drop=True)\n",
    "value_counts\n",
    "\n",
    "alt.Chart(value_counts).mark_bar().encode(\n",
    "    y='noun',\n",
    "    x='count',\n",
    "    color='borough',\n",
    "    column='session', \n",
    "    row='Weekday'\n",
    ").properties(\n",
    "    width=120,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "defbec6e-ad2a-4b1a-a906-dbc46b5169d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/2292067166.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_verb_borough['verb'] = df_verb_borough['verb'].apply(literal_eval)\n",
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/2292067166.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  value_counts = verb_counts.groupby('borough').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e6cffbb47f0245439dba9bc24eb8ddb8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e6cffbb47f0245439dba9bc24eb8ddb8.vega-embed details,\n",
       "  #altair-viz-e6cffbb47f0245439dba9bc24eb8ddb8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e6cffbb47f0245439dba9bc24eb8ddb8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e6cffbb47f0245439dba9bc24eb8ddb8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e6cffbb47f0245439dba9bc24eb8ddb8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-3b6f1b4eb0e239e934418c9c690e9658\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"borough\", \"type\": \"nominal\"}, \"column\": {\"field\": \"Weekday\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"verb\", \"type\": \"nominal\"}}, \"height\": 600, \"width\": 110, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-3b6f1b4eb0e239e934418c9c690e9658\": [{\"borough\": \"Brooklyn\", \"verb\": \"get\", \"Weekday\": 5, \"count\": 5}, {\"borough\": \"Brooklyn\", \"verb\": \"see\", \"Weekday\": 6, \"count\": 5}, {\"borough\": \"Brooklyn\", \"verb\": \"have\", \"Weekday\": 6, \"count\": 4}, {\"borough\": \"Brooklyn\", \"verb\": \"look\", \"Weekday\": 5, \"count\": 4}, {\"borough\": \"Brooklyn\", \"verb\": \"sit\", \"Weekday\": 5, \"count\": 4}, {\"borough\": \"Brooklyn\", \"verb\": \"think\", \"Weekday\": 5, \"count\": 4}, {\"borough\": \"Brooklyn\", \"verb\": \"want\", \"Weekday\": 1, \"count\": 4}, {\"borough\": \"Brooklyn\", \"verb\": \"have\", \"Weekday\": 1, \"count\": 3}, {\"borough\": \"Brooklyn\", \"verb\": \"keep\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Brooklyn\", \"verb\": \"like\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Manhattan\", \"verb\": \"get\", \"Weekday\": 2, \"count\": 9}, {\"borough\": \"Manhattan\", \"verb\": \"see\", \"Weekday\": 3, \"count\": 8}, {\"borough\": \"Manhattan\", \"verb\": \"have\", \"Weekday\": 5, \"count\": 7}, {\"borough\": \"Manhattan\", \"verb\": \"look\", \"Weekday\": 4, \"count\": 7}, {\"borough\": \"Manhattan\", \"verb\": \"say\", \"Weekday\": 1, \"count\": 7}, {\"borough\": \"Manhattan\", \"verb\": \"see\", \"Weekday\": 6, \"count\": 7}, {\"borough\": \"Manhattan\", \"verb\": \"see\", \"Weekday\": 2, \"count\": 6}, {\"borough\": \"Manhattan\", \"verb\": \"get\", \"Weekday\": 1, \"count\": 5}, {\"borough\": \"Manhattan\", \"verb\": \"have\", \"Weekday\": 4, \"count\": 5}, {\"borough\": \"Manhattan\", \"verb\": \"hope\", \"Weekday\": 6, \"count\": 5}, {\"borough\": \"Queens\", \"verb\": \"get\", \"Weekday\": 0, \"count\": 4}, {\"borough\": \"Queens\", \"verb\": \"ask\", \"Weekday\": 1, \"count\": 3}, {\"borough\": \"Queens\", \"verb\": \"ask\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"connect\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"like\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"live\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"live\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"look\", \"Weekday\": 4, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"love\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"verb\": \"make\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"have\", \"Weekday\": 4, \"count\": 3}, {\"borough\": \"Staten Island\", \"verb\": \"feel\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"give\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"make\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"meet\", \"Weekday\": 6, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"smile\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"take\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Staten Island\", \"verb\": \"arrive\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"verb\": \"become\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"verb\": \"believe\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"The Bronx\", \"verb\": \"get\", \"Weekday\": 2, \"count\": 3}, {\"borough\": \"The Bronx\", \"verb\": \"get\", \"Weekday\": 5, \"count\": 3}, {\"borough\": \"The Bronx\", \"verb\": \"get\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"The Bronx\", \"verb\": \"know\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"The Bronx\", \"verb\": \"notice\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"The Bronx\", \"verb\": \"talk\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"The Bronx\", \"verb\": \"want\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"The Bronx\", \"verb\": \"ask\", \"Weekday\": 5, \"count\": 1}, {\"borough\": \"The Bronx\", \"verb\": \"be\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"The Bronx\", \"verb\": \"believe\", \"Weekday\": 2, \"count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_verb_borough = df[['verb', 'borough', 'Weekday']]\n",
    "df_verb_borough['verb'] = df_verb_borough['verb'].apply(literal_eval)\n",
    "df_verb_exploded = df_verb_borough.explode('verb')\n",
    "# # Group by 'borough' and get the value counts for 'nouns'\n",
    "verb_counts = df_verb_exploded.groupby(['borough', 'verb', 'Weekday']).size().reset_index(name='count')\n",
    "# noun_counts\n",
    "value_counts = verb_counts.groupby('borough').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "\n",
    "\n",
    "alt.Chart(value_counts).mark_bar().encode(\n",
    "    y='verb',\n",
    "    x='count',\n",
    "    color='borough',\n",
    "    column='Weekday', \n",
    "    \n",
    ").properties(\n",
    "    width=110,\n",
    "    height=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb2f99eb-8a8c-4a96-8601-d99df4f7a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/3772940253.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_adj_borough['adj'] = df_adj_borough['adj'].apply(literal_eval)\n",
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14889/3772940253.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  adj_value_counts = adj_counts.groupby('borough').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e4ba7c4e229345f4a987e8cfcc09cd12.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e4ba7c4e229345f4a987e8cfcc09cd12.vega-embed details,\n",
       "  #altair-viz-e4ba7c4e229345f4a987e8cfcc09cd12.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e4ba7c4e229345f4a987e8cfcc09cd12\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e4ba7c4e229345f4a987e8cfcc09cd12\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e4ba7c4e229345f4a987e8cfcc09cd12\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-7554a2c6bd9a81cd96edcbe3cf231bbe\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"borough\", \"type\": \"nominal\"}, \"column\": {\"field\": \"Weekday\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"adj\", \"type\": \"nominal\"}}, \"height\": 600, \"width\": 110, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-7554a2c6bd9a81cd96edcbe3cf231bbe\": [{\"borough\": \"Brooklyn\", \"adj\": \"black\", \"Weekday\": 3, \"count\": 3}, {\"borough\": \"Brooklyn\", \"adj\": \"few\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Brooklyn\", \"adj\": \"white\", \"Weekday\": 3, \"count\": 3}, {\"borough\": \"Brooklyn\", \"adj\": \"beautiful\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"Brooklyn\", \"adj\": \"beautiful\", \"Weekday\": 6, \"count\": 2}, {\"borough\": \"Brooklyn\", \"adj\": \"black\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Brooklyn\", \"adj\": \"black\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"Brooklyn\", \"adj\": \"black\", \"Weekday\": 6, \"count\": 2}, {\"borough\": \"Brooklyn\", \"adj\": \"blue\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"Brooklyn\", \"adj\": \"blue\", \"Weekday\": 6, \"count\": 2}, {\"borough\": \"Manhattan\", \"adj\": \"black\", \"Weekday\": 2, \"count\": 5}, {\"borough\": \"Manhattan\", \"adj\": \"black\", \"Weekday\": 3, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"black\", \"Weekday\": 5, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"black\", \"Weekday\": 6, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"good\", \"Weekday\": 4, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"other\", \"Weekday\": 0, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"red\", \"Weekday\": 2, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"white\", \"Weekday\": 2, \"count\": 3}, {\"borough\": \"Manhattan\", \"adj\": \"4th\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Manhattan\", \"adj\": \"beautiful\", \"Weekday\": 2, \"count\": 2}, {\"borough\": \"Queens\", \"adj\": \"cute\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"adj\": \"same\", \"Weekday\": 0, \"count\": 2}, {\"borough\": \"Queens\", \"adj\": \"sick\", \"Weekday\": 1, \"count\": 2}, {\"borough\": \"Queens\", \"adj\": \"about\", \"Weekday\": 1, \"count\": 1}, {\"borough\": \"Queens\", \"adj\": \"beautiful\", \"Weekday\": 1, \"count\": 1}, {\"borough\": \"Queens\", \"adj\": \"beautiful\", \"Weekday\": 5, \"count\": 1}, {\"borough\": \"Queens\", \"adj\": \"black\", \"Weekday\": 1, \"count\": 1}, {\"borough\": \"Queens\", \"adj\": \"blue\", \"Weekday\": 0, \"count\": 1}, {\"borough\": \"Queens\", \"adj\": \"bottom\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"Queens\", \"adj\": \"curious\", \"Weekday\": 0, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"asian\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"beautiful\", \"Weekday\": 0, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"big\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"express\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"female\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"few\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"free\", \"Weekday\": 6, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"good\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"good\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"Staten Island\", \"adj\": \"great\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"beautiful\", \"Weekday\": 3, \"count\": 2}, {\"borough\": \"The Bronx\", \"adj\": \"dark\", \"Weekday\": 5, \"count\": 2}, {\"borough\": \"The Bronx\", \"adj\": \"amazing\", \"Weekday\": 3, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"amazing\", \"Weekday\": 4, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"amazing\", \"Weekday\": 5, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"beard\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"beautiful\", \"Weekday\": 2, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"beautiful\", \"Weekday\": 5, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"big\", \"Weekday\": 3, \"count\": 1}, {\"borough\": \"The Bronx\", \"adj\": \"black\", \"Weekday\": 2, \"count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj_borough = df[['adj', 'borough', 'Weekday']]\n",
    "df_adj_borough['adj'] = df_adj_borough['adj'].apply(literal_eval)\n",
    "df_adj_exploded = df_adj_borough.explode('adj')\n",
    "\n",
    "# # Group by 'borough' and get the value counts for 'nouns'\n",
    "adj_counts = df_adj_exploded.groupby(['borough', 'adj', 'Weekday']).size().reset_index(name='count')\n",
    "# noun_counts\n",
    "adj_value_counts = adj_counts.groupby('borough').apply(lambda x: x.nlargest(10, 'count')).reset_index(drop=True)\n",
    "\n",
    "\n",
    "alt.Chart(adj_value_counts).mark_bar().encode(\n",
    "    y='adj',\n",
    "    x='count',\n",
    "    color='borough',\n",
    "    column='Weekday', \n",
    "    \n",
    ").properties(\n",
    "    width=110,\n",
    "    height=600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72833d51-533f-4a10-837c-10f740d12c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14366/56151571.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_noun_borough['noun'] = df_noun_borough['noun'].apply(literal_eval)\n",
      "/var/folders/9m/cnc48ycx4xbc6n754r3xlv2h0000gn/T/ipykernel_14366/56151571.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  value_counts = noun_counts.groupby('borough').apply(lambda x: x.nlargest(5, 'count')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7416bbf246a74731ae0ee6c4d3329e8b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7416bbf246a74731ae0ee6c4d3329e8b.vega-embed details,\n",
       "  #altair-viz-7416bbf246a74731ae0ee6c4d3329e8b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7416bbf246a74731ae0ee6c4d3329e8b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7416bbf246a74731ae0ee6c4d3329e8b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7416bbf246a74731ae0ee6c4d3329e8b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-09772782c7efc1d3e798f094f31a0092\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"borough\", \"type\": \"nominal\"}, \"column\": {\"field\": \"Weekday\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"noun\", \"type\": \"nominal\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-09772782c7efc1d3e798f094f31a0092\": [{\"borough\": \"Brooklyn\", \"Weekday\": 1, \"noun\": \"friend\", \"count\": 4}, {\"borough\": \"Brooklyn\", \"Weekday\": 5, \"noun\": \"friend\", \"count\": 4}, {\"borough\": \"Brooklyn\", \"Weekday\": 6, \"noun\": \"eye\", \"count\": 4}, {\"borough\": \"Brooklyn\", \"Weekday\": 0, \"noun\": \"woman\", \"count\": 3}, {\"borough\": \"Brooklyn\", \"Weekday\": 5, \"noun\": \"shirt\", \"count\": 3}, {\"borough\": \"Manhattan\", \"Weekday\": 2, \"noun\": \"eye\", \"count\": 8}, {\"borough\": \"Manhattan\", \"Weekday\": 4, \"noun\": \"guy\", \"count\": 7}, {\"borough\": \"Manhattan\", \"Weekday\": 1, \"noun\": \"train\", \"count\": 5}, {\"borough\": \"Manhattan\", \"Weekday\": 2, \"noun\": \"train\", \"count\": 5}, {\"borough\": \"Manhattan\", \"Weekday\": 5, \"noun\": \"train\", \"count\": 5}, {\"borough\": \"Queens\", \"Weekday\": 0, \"noun\": \"time\", \"count\": 5}, {\"borough\": \"Queens\", \"Weekday\": 0, \"noun\": \"eye\", \"count\": 3}, {\"borough\": \"Queens\", \"Weekday\": 0, \"noun\": \"contact\", \"count\": 2}, {\"borough\": \"Queens\", \"Weekday\": 0, \"noun\": \"guy\", \"count\": 2}, {\"borough\": \"Queens\", \"Weekday\": 0, \"noun\": \"past\", \"count\": 2}, {\"borough\": \"Staten Island\", \"Weekday\": 4, \"noun\": \"guy\", \"count\": 3}, {\"borough\": \"Staten Island\", \"Weekday\": 2, \"noun\": \"approach\", \"count\": 2}, {\"borough\": \"Staten Island\", \"Weekday\": 2, \"noun\": \"bike\", \"count\": 2}, {\"borough\": \"Staten Island\", \"Weekday\": 2, \"noun\": \"parking\", \"count\": 2}, {\"borough\": \"Staten Island\", \"Weekday\": 2, \"noun\": \"pm\", \"count\": 2}, {\"borough\": \"The Bronx\", \"Weekday\": 0, \"noun\": \"guy\", \"count\": 2}, {\"borough\": \"The Bronx\", \"Weekday\": 2, \"noun\": \"tee\", \"count\": 2}, {\"borough\": \"The Bronx\", \"Weekday\": 3, \"noun\": \"kit\", \"count\": 2}, {\"borough\": \"The Bronx\", \"Weekday\": 0, \"noun\": \"50am\", \"count\": 1}, {\"borough\": \"The Bronx\", \"Weekday\": 0, \"noun\": \"86th\", \"count\": 1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noun_borough = df[['noun', 'borough', 'Weekday']]\n",
    "df_noun_borough['noun'] = df_noun_borough['noun'].apply(literal_eval)\n",
    "df_exploded = df_noun_borough.explode('noun')\n",
    "df_exploded\n",
    "# # Group by 'borough' and get the value counts for 'nouns'\n",
    "noun_counts = df_exploded.groupby(['borough', 'Weekday', 'noun']).size().reset_index(name='count')\n",
    "# noun_counts\n",
    "value_counts = noun_counts.groupby('borough').apply(lambda x: x.nlargest(5, 'count')).reset_index(drop=True)\n",
    "value_counts\n",
    "\n",
    "alt.Chart(value_counts).mark_bar().encode(\n",
    "    y='noun',\n",
    "    x='count',\n",
    "    color='borough',\n",
    "    column='Weekday'\n",
    ")\n",
    "\n",
    "## noun to replace t, tee, and shirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9616cde1-5914-4848-a635-31673189337c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>connection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queens</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>kit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>tee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>nail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bronx</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>beard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     borough        noun\n",
       "0  Manhattan         eye\n",
       "0  Manhattan         guy\n",
       "0  Manhattan       train\n",
       "0  Manhattan        time\n",
       "0  Manhattan       shirt\n",
       "0  Manhattan      friend\n",
       "0  Manhattan        hair\n",
       "0  Manhattan      number\n",
       "0  Manhattan       dress\n",
       "0  Manhattan       short\n",
       "1   Brooklyn      friend\n",
       "1   Brooklyn         eye\n",
       "1   Brooklyn       woman\n",
       "1   Brooklyn       train\n",
       "1   Brooklyn       shirt\n",
       "1   Brooklyn           t\n",
       "1   Brooklyn        time\n",
       "1   Brooklyn       night\n",
       "1   Brooklyn         guy\n",
       "1   Brooklyn        hair\n",
       "2     Queens         eye\n",
       "2     Queens        time\n",
       "2     Queens       smile\n",
       "2     Queens     contact\n",
       "2     Queens       train\n",
       "2     Queens        work\n",
       "2     Queens         man\n",
       "2     Queens  connection\n",
       "2     Queens        beat\n",
       "2     Queens      number\n",
       "3      Bronx         guy\n",
       "3      Bronx       train\n",
       "3      Bronx         kit\n",
       "3      Bronx        hair\n",
       "3      Bronx         tee\n",
       "3      Bronx     morning\n",
       "3      Bronx     message\n",
       "3      Bronx        park\n",
       "3      Bronx        nail\n",
       "3      Bronx       month\n",
       "4   Brooklyn     contact\n",
       "4   Brooklyn         guy\n",
       "4   Brooklyn       woman\n",
       "4   Brooklyn        door\n",
       "4   Brooklyn       beard\n",
       "4   Brooklyn        bike\n",
       "4   Brooklyn    approach\n",
       "4   Brooklyn          pm\n",
       "4   Brooklyn        time\n",
       "4   Brooklyn       dress"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top five nouns in each borough in dataframe \n",
    "data = {\n",
    "    'borough': ['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island'],\n",
    "    'noun': [\n",
    "        ['eye', 'guy', 'train', 'time', 'shirt', 'friend', 'hair', 'number', 'dress', 'short'],\n",
    "        ['friend', 'eye', 'woman', 'train', 'shirt', 't', 'time', 'night', 'guy', 'hair'],\n",
    "        ['eye', 'time', 'smile', 'contact', 'train', 'work', 'man', 'connection', 'beat', 'number'],\n",
    "        ['guy', 'train', 'kit', 'hair', 'tee', 'morning', 'message', 'park', 'nail', 'month'],\n",
    "        ['contact', 'guy', 'woman', 'door', 'beard', 'bike', 'approach', 'pm', 'time', 'dress']\n",
    "    ]\n",
    "}\n",
    "\n",
    "topnoun = pd.DataFrame(data)\n",
    "\n",
    "# topnoun['noun'] = topnoun['noun'].apply(literal_eval)\n",
    "topnoun_exploded = topnoun.explode('noun')\n",
    "topnoun_exploded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
